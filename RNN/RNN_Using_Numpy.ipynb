{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Bf2zNKPlIVbJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"is this working good\"\n",
        "\n",
        "chars = list(set(data))\n",
        "\n",
        "print(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeoUB1eCIlfX",
        "outputId": "0d09246f-3552-4e7d-f711-6568f64abd56"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['o', 'w', ' ', 'k', 'h', 't', 'r', 'g', 's', 'i', 'n', 'd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mapping\n",
        "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
        "print(char_to_idx)\n",
        "idx_to_char = {i: ch for ch, i in char_to_idx.items()}\n",
        "print(idx_to_char)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdEfeVtrIsWi",
        "outputId": "68c4a0e7-688f-4b3e-8e60-2defedb91a32"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'o': 0, 'w': 1, ' ': 2, 'k': 3, 'h': 4, 't': 5, 'r': 6, 'g': 7, 's': 8, 'i': 9, 'n': 10, 'd': 11}\n",
            "{0: 'o', 1: 'w', 2: ' ', 3: 'k', 4: 'h', 5: 't', 6: 'r', 7: 'g', 8: 's', 9: 'i', 10: 'n', 11: 'd'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(chars)\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCtaEJ7fI72u",
        "outputId": "50326f5a-42c7-462a-d091-2ff2e7f37efd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(idx, size):\n",
        "    vec = np.zeros((size, 1))\n",
        "    vec[idx] = 1\n",
        "    return vec"
      ],
      "metadata": {
        "id": "AHzB404tJNPW"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###RNN"
      ],
      "metadata": {
        "id": "yGE74dCJJdlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN:\n",
        "  def __init__(self,input_size,hidden_size,output_size,learning_rate = 0.01):\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "    #Weight matrics for input->hidden, hidden->hidden, hidden->output\n",
        "    self.U = np.random.randn(hidden_size,input_size) * 0.01\n",
        "    self.W = np.random.randn(hidden_size,hidden_size) * 0.01\n",
        "    self.V = np.random.randn(output_size,hidden_size) * 0.01\n",
        "\n",
        "    # Biases for hidden and output layers\n",
        "    self.b = np.zeros((hidden_size,1))\n",
        "    self.c = np.zeros((output_size,1))\n",
        "\n",
        "  def softmax(self,x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    h = {}  #store hidden states at each time step\n",
        "    y_hat = {}  #stores predictions at each time step\n",
        "    h[-1] = np.zeros((self.hidden_size,1)) #initial hidden state = 0\n",
        "\n",
        "    for t in range(len(inputs)):\n",
        "      x = inputs[t] # One - hot encoded input at time t\n",
        "\n",
        "      # Hidden state:\n",
        "      h[t] = np.tanh(np.dot(self.U,x) + np.dot(self.W,h[t-1]) + self.b)\n",
        "\n",
        "      #Output Prediction:\n",
        "      y = np.dot(self.V,h[t]) + self.c\n",
        "\n",
        "      #Softmax output:\n",
        "      y_hat[t] = self.softmax(y)\n",
        "\n",
        "    return y_hat,h #Return outputs and hidden states\n",
        "\n",
        "  def compute_loss(self,y_hat,targets):\n",
        "    loss = 0\n",
        "    for t in range(len(targets)):\n",
        "      loss -= np.log(y_hat[t][targets[t],0])\n",
        "    return loss\n",
        "\n",
        "  def bptt(self,inputs,targets,y_hat,h):\n",
        "    dU = np.zeros_like(self.U)\n",
        "    dW = np.zeros_like(self.W)\n",
        "    dV = np.zeros_like(self.V)\n",
        "    db = np.zeros_like(self.b)\n",
        "    dc = np.zeros_like(self.c)\n",
        "\n",
        "    dh_next = np.zeros_like(h[0]) #gradient for next hidden state\n",
        "\n",
        "    #iterate backward\n",
        "    for t in reversed(range(len(inputs))):\n",
        "      dy = np.copy(y_hat[t])\n",
        "      dy[targets[t]] -= 1\n",
        "\n",
        "      #Gradient for output layers\n",
        "      dV += np.dot(dy,h[t].T)\n",
        "      dc += dy\n",
        "\n",
        "      #backprop into hidden layer\n",
        "      dh = np.dot(self.V.T,dy) + dh_next\n",
        "\n",
        "      #backprop through tanh\n",
        "      dtanh = (1-h[t]**2) * dh\n",
        "      db += dtanh\n",
        "      dU += np.dot(dtanh,inputs[t].T)\n",
        "      dW += np.dot(dtanh,h[t-1].T)\n",
        "\n",
        "      dh_next = np.dot(self.W.T,dtanh)\n",
        "\n",
        "    return dU,dW,dV,db,dc\n",
        "\n",
        "  def update(self,dU,dW,dV,db,dc):\n",
        "    for param,dparam in zip([self.U,self.W,self.V,self.b,self.c],\n",
        "                            [dU,dW,dV,db,dc]):\n",
        "      param -= self.learning_rate * dparam\n",
        "\n",
        "  def train_step(self,inputs,targets):\n",
        "\n",
        "    y_hat ,h = self.forward(inputs)\n",
        "\n",
        "    loss = self.compute_loss(y_hat,targets)\n",
        "\n",
        "    dU,dW,dV,db,dc = self.bptt(inputs,targets,y_hat,h)\n",
        "\n",
        "    self.update(dU,dW,dV,db,dc)\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def predict(self,start_char,n=10):\n",
        "    #Predict next n charaters\n",
        "    idx = char_to_idx[start_char]\n",
        "    x = one_hot_encode(idx,self.input_size)\n",
        "    h_prev = np.zeros((self.hidden_size,1))\n",
        "    output = start_char\n",
        "\n",
        "    for _ in range(n):\n",
        "      #compute hidden state\n",
        "      h_prev = np.tanh(np.dot(self.U,x) + np.dot(self.W,h_prev) + self.b)\n",
        "\n",
        "      y = np.dot(self.V,h_prev) + self.c\n",
        "\n",
        "      y_hat = self.softmax(y)\n",
        "\n",
        "      idx = np.argmax(y_hat)\n",
        "\n",
        "      x = one_hot_encode(idx,self.input_size)\n",
        "      output += idx_to_char[idx]\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "1QKP-pLiJjAf"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert entire input sequence to one-hot vectors\n",
        "inputs = [one_hot_encode(char_to_idx[ch], vocab_size) for ch in data[:-1]]\n",
        "targets = [char_to_idx[ch] for ch in data[1:]]\n",
        "\n",
        "#RNN model\n",
        "rnn = RNN(input_size=vocab_size, hidden_size=64, output_size=vocab_size)\n",
        "\n",
        "# Train for N epochs\n",
        "epochs = 300\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss = rnn.train_step(inputs, targets)  # One step of forward + backward + update\n",
        "\n",
        "    # Print every 50 epochs\n",
        "    if epoch % 50 == 0 or epoch == 1:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "        print(\"Prediction:\", rnn.predict(\"i\", n=19))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thlURYEjJi9m",
        "outputId": "f7cc12ca-39a9-42f0-9075-23bbc9251324"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 47.2115\n",
            "Prediction: io o o o o o o o o o\n",
            "Epoch 50, Loss: 45.3053\n",
            "Prediction: iooooooooooooooooooo\n",
            "Epoch 100, Loss: 43.3859\n",
            "Prediction: iooooooooooooooooooo\n",
            "Epoch 150, Loss: 32.3573\n",
            "Prediction: is goooooooooooooooo\n",
            "Epoch 200, Loss: 9.9147\n",
            "Prediction: is tois working good\n",
            "Epoch 250, Loss: 2.9154\n",
            "Prediction: is this working good\n",
            "Epoch 300, Loss: 1.2075\n",
            "Prediction: is this working good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e9-F_J2iJi6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J880rnaNJi3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iNEumx0RJi1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qmSTEmOjJiyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQPiNMWPJivf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}